{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# load data\n",
    "from torch.utils.data import DataLoader\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "# train\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.nn.init\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_df = pd.read_csv('test_tables/test_table(20*1000).csv', encoding='UTF-8', engine = 'python')\n",
    "result_table = pd.read_csv('./result_tables/result_table.csv', engine='python', encoding='utf-8')\n",
    "result_table = result_table.set_index('index')\n",
    "result_table = result_table.replace(np.nan, 0)\n",
    "\n",
    "batch_size = []\n",
    "training_epochs = []\n",
    "layer1_ks = []\n",
    "layer1_MP = []\n",
    "layer2_ks = []\n",
    "layer2_MP = []\n",
    "layer3_ks = []\n",
    "layer3_MP = []\n",
    "fc1_to = []\n",
    "fc1_bias = [] \n",
    "fc2_bias = []\n",
    "\n",
    "num_workers = 40\n",
    "\n",
    "for i in range(1, 145):\n",
    "    batch_size.append(test_df.iloc[0, i])\n",
    "    training_epochs.append(test_df.iloc[1, i])\n",
    "    layer1_ks.append(test_df.iloc[2, i])\n",
    "    layer1_MP.append(test_df.iloc[3, i])\n",
    "    layer2_ks.append(test_df.iloc[4, i])\n",
    "    layer2_MP.append(test_df.iloc[5, i])\n",
    "    layer3_ks.append(test_df.iloc[6, i])\n",
    "    layer3_MP.append(test_df.iloc[7, i])\n",
    "    fc1_to.append(test_df.iloc[8, i])\n",
    "    fc1_bias.append(test_df.iloc[9, i])\n",
    "    fc2_bias.append(test_df.iloc[10, i])\n",
    "\n",
    "def read_csv(file_name):\n",
    "    df = pd.read_csv(file_name, header=None)\n",
    "    return df\n",
    "\n",
    "\n",
    "class MFCCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        pool = mp.Pool(processes = 100)\n",
    "        start = time.time()\n",
    "        self.raw = pd.concat(pool.map(read_csv, file_list))\n",
    "        print(\"time :\", time.time() - start)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        \n",
    "        self.label = torch.IntTensor(np.array(self.raw[0].values).reshape(len(self.raw[0].values), 1))\n",
    "        self.len = len(self.label)\n",
    "        self.data = torch.Tensor(np.array(self.raw.loc[:,1:]).reshape(len(self.label),20,1000))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=layer1_ks[i], stride=1, padding=int(layer1_ks[i]/2)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=layer1_MP[i], stride=layer1_MP[i]))\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=layer2_ks[i], stride=1, padding=int(layer2_ks[i]/2)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=layer2_MP[i], stride=layer2_MP[i]))\n",
    "\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=layer3_ks[i], stride=1, padding=int(layer3_ks[i]/2)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=layer3_MP[i], stride=layer3_MP[i]))\n",
    "\n",
    "        denom = (128*20*1000)/((layer1_MP[i]*layer2_MP[i]*layer3_MP[i])*(layer1_MP[i]*layer2_MP[i]*layer3_MP[i]))\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(int(denom), fc1_to[i], bias=bool(fc1_bias[i]))\n",
    "        self.fc2 = torch.nn.Linear(fc1_to[i], 3, bias=bool(fc2_bias[i]))\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        #torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "        dropout = torch.nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "import random\n",
    "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\\\n",
    "print(\"다음 기기로 학습합니다:\", device)\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "\n",
    "train_list = []\n",
    "for i in range(26):\n",
    "    train_list.append('./separated data4(20*1000)/train'+str(i+1)+'.csv')\n",
    "\n",
    "test_list = []\n",
    "for i in range(7):\n",
    "    test_list.append('./separated data4(20*1000)/test'+str(i+1)+'.csv')\n",
    "\n",
    "\n",
    "\n",
    "for i in range(144):\n",
    "    sum_test_accuracy = 0\n",
    "    sum_test_inference_time = 0\n",
    "    max_test_accuracy = -1\n",
    "    for j in range(5):\n",
    "        print(\"Loading data...\")\n",
    "        \n",
    "        dataset = MFCCDataset(train_list)\n",
    "\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size = int(batch_size[i]), num_workers = num_workers, drop_last=True\n",
    "            )\n",
    "        print(\"data is ready!\")\n",
    "\n",
    "        # CNN 모델 정의\n",
    "        learning_rate = 0.001\n",
    "        training_epoch = training_epochs[i]\n",
    "        model = CNN() \n",
    "        model = torch.nn.DataParallel(model)\n",
    "        model.cuda()\n",
    "        criterion = torch.nn.CrossEntropyLoss() \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        total_batch = len(dataloader)\n",
    "        print('총 배치의 수 : {}'.format(total_batch))\n",
    "\n",
    "        global_step = 0\n",
    "        for epoch in range(training_epoch):\n",
    "            avg_cost = 0\n",
    "\n",
    "            for X, Y in dataloader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n",
    "                # image is already size of (28x28), no reshape\n",
    "                # label is not one-hot encoded\n",
    "                X = X.reshape(batch_size[i],1,20,1000).to(device)\n",
    "                Y = Y.reshape(batch_size[i],1)[:,0].to(device, dtype=torch.int64)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                hypothesis = model(X)\n",
    "                cost = criterion(hypothesis, Y)\n",
    "                cost.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                avg_cost += cost / total_batch\n",
    "\n",
    "            print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
    "\n",
    "        print(\"Loading testset...\")\n",
    "\n",
    "        testset = MFCCDataset(test_list)\n",
    "\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size = int(batch_size[i]), num_workers = num_workers, shuffle=True, drop_last=True\n",
    "        )\n",
    "        print(\"testset is ready!\")\n",
    "\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            X_test = testset.data.view(len(testset), 1, 20, 1000).float().to(device)\n",
    "            Y_test = testset.label.to(device, dtype=torch.int64)[:,0]\n",
    "\n",
    "            prediction = model(X_test)\n",
    "            correct_prediction = torch.argmax(prediction, 1) == Y_test \n",
    "            accuracy = correct_prediction.float().mean()\n",
    "            print('Accuracy:', accuracy.item())\n",
    "        if(accuracy.item() > max_test_accuracy):\n",
    "            max_test_accuracy = accuracy.item()\n",
    "\n",
    "        sum_test_accuracy += accuracy.item()\n",
    "        sum_test_inference_time += time.time() - start \n",
    "        result_table.iloc[i][2*j] = accuracy.item()\n",
    "        result_table.iloc[i][2*j+1] = time.time() - start \n",
    "\n",
    "        print(\"time :\", time.time() - start, \"\\n\\n\")\n",
    "    print(str(i+1)+'번째 테스트' +str(j+1) + '회 학습 avg_accuracy : '+str(sum_test_accuracy/10)+' avg_inference_time : '+str(sum_test_inference_time/10)+\"\\n\\n\")\n",
    "    result_table.iloc[i][10] = sum_test_accuracy/10\n",
    "    result_table.iloc[i][11] = sum_test_inference_time/10"
   ]
  }
 ]
}