{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "kc",
   "display_name": "KC",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1. File Loading"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# load data\n",
    "from torch.utils.data import DataLoader\n",
    "import multiprocessing as mp\n",
    "\n",
    "# train\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.nn.init\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def processing_chunk(chunk):\n",
    "#     for row in chunk.iterrows():\n",
    "#         pass\n",
    "#     time.sleep(5)\n",
    "\n",
    "# def mp_csv_read(filename):\n",
    "#     pool_size = 80\n",
    "#     pool = mp.Pool(pool_size)\n",
    "#     chunk_size = 1000 * pool_size\n",
    "#     count = 0\n",
    "#     for file_chunk in pd.read_csv(filename', chunksize=chunk_size):\n",
    "#         line = count * chunk_size\n",
    "#         print(f\"Processing {chunk_size} lines after line {line}\")\n",
    "        \n",
    "#         # Split chunk evenly. It's better to use this method if every chunk takes similar time.\n",
    "#         pool.map(processing_chunk, pd.np.array_split(file_chunk, pool_size))\n",
    "\n",
    "#         count += 1\n",
    "\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 40\n",
    "writer = SummaryWriter('runs/MFCC')\n",
    "train_set = 'slim_train_set3.csv'\n",
    "test_set = 'slim_test_set3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading data...\n",
      "data is ready!\n"
     ]
    }
   ],
   "source": [
    "class MFCCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.raw = pd.read_csv(csv_file, header=None)\n",
    "        self.label = torch.IntTensor(np.array(self.raw[0].values).reshape(len(self.raw[0].values), 1))\n",
    "        self.len = len(self.label)\n",
    "        self.data = torch.Tensor(np.array(self.raw.loc[:,1:]).reshape(len(self.label),100,500))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "dataset = MFCCDataset(train_set)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "   dataset, batch_size = batch_size, num_workers = num_workers, drop_last=True\n",
    ")\n",
    "print(\"data is ready!\")"
   ]
  },
  {
   "source": [
    "# 2. Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "다음 기기로 학습합니다: cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\\\n",
    "print(\"다음 기기로 학습합니다:\", device)\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 첫번째층\n",
    "        # ImgIn shape=(?, 28, 28, 1) -> 1, 100, 1000, 1\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=13, stride=1, padding=6),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=10, stride=10))\n",
    "\n",
    "        # 두번째층\n",
    "        # ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=7, stride=1, padding=3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=5, stride=5))\n",
    "\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
    "        self.fc = torch.nn.Linear(1 * 5 * 128, 3, bias=True)\n",
    "\n",
    "        # 전결합층 한정으로 가중치 초기화\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "총 배치의 수 : 81\n"
     ]
    }
   ],
   "source": [
    "# CNN 모델 정의\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "model = CNN()   #.to(device)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss() #.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "total_batch = len(dataloader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoch:    1] cost = 1.11157501\n",
      "[Epoch:    2] cost = 1.02012336\n",
      "[Epoch:    3] cost = 0.858102202\n",
      "[Epoch:    4] cost = 0.768326759\n",
      "[Epoch:    5] cost = 0.696729243\n",
      "[Epoch:    6] cost = 0.649398863\n",
      "[Epoch:    7] cost = 0.609773755\n",
      "[Epoch:    8] cost = 0.562349737\n",
      "[Epoch:    9] cost = 0.513740718\n",
      "[Epoch:   10] cost = 0.471781164\n",
      "[Epoch:   11] cost = 0.433978438\n",
      "[Epoch:   12] cost = 0.416911751\n",
      "[Epoch:   13] cost = 0.400634646\n",
      "[Epoch:   14] cost = 0.397368819\n",
      "[Epoch:   15] cost = 0.403248578\n",
      "[Epoch:   16] cost = 0.403770983\n",
      "[Epoch:   17] cost = 0.409146816\n",
      "[Epoch:   18] cost = 0.381402433\n",
      "[Epoch:   19] cost = 0.352811724\n",
      "[Epoch:   20] cost = 0.333272606\n",
      "[Epoch:   21] cost = 0.312036812\n",
      "[Epoch:   22] cost = 0.280128926\n",
      "[Epoch:   23] cost = 0.27647993\n",
      "[Epoch:   24] cost = 0.249866053\n",
      "[Epoch:   25] cost = 0.230445594\n",
      "[Epoch:   26] cost = 0.217129782\n",
      "[Epoch:   27] cost = 0.224300578\n",
      "[Epoch:   28] cost = 0.220739231\n",
      "[Epoch:   29] cost = 0.222180828\n",
      "[Epoch:   30] cost = 0.242725074\n",
      "[Epoch:   31] cost = 0.247402191\n",
      "[Epoch:   32] cost = 0.218484849\n",
      "[Epoch:   33] cost = 0.256445706\n",
      "[Epoch:   34] cost = 0.292686939\n",
      "[Epoch:   35] cost = 0.251772821\n",
      "[Epoch:   36] cost = 0.261697471\n",
      "[Epoch:   37] cost = 0.26402387\n",
      "[Epoch:   38] cost = 0.241540566\n",
      "[Epoch:   39] cost = 0.178415835\n",
      "[Epoch:   40] cost = 0.157913908\n",
      "[Epoch:   41] cost = 0.160658166\n",
      "[Epoch:   42] cost = 0.16149044\n",
      "[Epoch:   43] cost = 0.174622238\n",
      "[Epoch:   44] cost = 0.141433612\n",
      "[Epoch:   45] cost = 0.129169166\n",
      "[Epoch:   46] cost = 0.170450419\n",
      "[Epoch:   47] cost = 0.141143948\n",
      "[Epoch:   48] cost = 0.145189673\n",
      "[Epoch:   49] cost = 0.168991655\n",
      "[Epoch:   50] cost = 0.181986272\n",
      "[Epoch:   51] cost = 0.186194867\n",
      "[Epoch:   52] cost = 0.196702376\n",
      "[Epoch:   53] cost = 0.206689775\n",
      "[Epoch:   54] cost = 0.179310873\n",
      "[Epoch:   55] cost = 0.156775892\n",
      "[Epoch:   56] cost = 0.12968725\n",
      "[Epoch:   57] cost = 0.0855236128\n",
      "[Epoch:   58] cost = 0.0686685592\n",
      "[Epoch:   59] cost = 0.0489829034\n",
      "[Epoch:   60] cost = 0.0508104861\n",
      "[Epoch:   61] cost = 0.0729177594\n",
      "[Epoch:   62] cost = 0.0562623776\n",
      "[Epoch:   63] cost = 0.0600868799\n",
      "[Epoch:   64] cost = 0.0975149348\n",
      "[Epoch:   65] cost = 0.058941856\n",
      "[Epoch:   66] cost = 0.0407820977\n",
      "[Epoch:   67] cost = 0.0501399823\n",
      "[Epoch:   68] cost = 0.0504495353\n",
      "[Epoch:   69] cost = 0.059655875\n",
      "[Epoch:   70] cost = 0.0350074209\n",
      "[Epoch:   71] cost = 0.047362674\n",
      "[Epoch:   72] cost = 0.0615073219\n",
      "[Epoch:   73] cost = 0.0592266172\n",
      "[Epoch:   74] cost = 0.0282671712\n",
      "[Epoch:   75] cost = 0.0457237326\n",
      "[Epoch:   76] cost = 0.0372209884\n",
      "[Epoch:   77] cost = 0.0283520874\n",
      "[Epoch:   78] cost = 0.0263470151\n",
      "[Epoch:   79] cost = 0.0337350145\n",
      "[Epoch:   80] cost = 0.0319666266\n",
      "[Epoch:   81] cost = 0.0326585472\n",
      "[Epoch:   82] cost = 0.0327237844\n",
      "[Epoch:   83] cost = 0.0313651226\n",
      "[Epoch:   84] cost = 0.0345261432\n",
      "[Epoch:   85] cost = 0.0353753529\n",
      "[Epoch:   86] cost = 0.038526345\n",
      "[Epoch:   87] cost = 0.0412254632\n",
      "[Epoch:   88] cost = 0.045740094\n",
      "[Epoch:   89] cost = 0.108947709\n",
      "[Epoch:   90] cost = 0.0553313792\n",
      "[Epoch:   91] cost = 0.0323804021\n",
      "[Epoch:   92] cost = 0.0282837451\n",
      "[Epoch:   93] cost = 0.0254791528\n",
      "[Epoch:   94] cost = 0.0507166721\n",
      "[Epoch:   95] cost = 0.076425761\n",
      "[Epoch:   96] cost = 0.150194392\n",
      "[Epoch:   97] cost = 0.063819088\n",
      "[Epoch:   98] cost = 0.0426801331\n",
      "[Epoch:   99] cost = 0.0192353409\n",
      "[Epoch:  100] cost = 0.0151331313\n",
      "[Epoch:  101] cost = 0.0182140023\n",
      "[Epoch:  102] cost = 0.0143704824\n",
      "[Epoch:  103] cost = 0.00731083844\n",
      "[Epoch:  104] cost = 0.00102755369\n",
      "[Epoch:  105] cost = 0.000415318209\n",
      "[Epoch:  106] cost = 0.000324336841\n",
      "[Epoch:  107] cost = 0.000286361901\n",
      "[Epoch:  108] cost = 0.000258607935\n",
      "[Epoch:  109] cost = 0.000236663342\n",
      "[Epoch:  110] cost = 0.000218391011\n",
      "[Epoch:  111] cost = 0.000202867799\n",
      "[Epoch:  112] cost = 0.000189627463\n",
      "[Epoch:  113] cost = 0.000177837457\n",
      "[Epoch:  114] cost = 0.00016722102\n",
      "[Epoch:  115] cost = 0.000157871866\n",
      "[Epoch:  116] cost = 0.000149287735\n",
      "[Epoch:  117] cost = 0.000141481112\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-917ba74a7dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# image is already size of (28x28), no reshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# label is not one-hot encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in dataloader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.reshape(32,1,100,500).to(device)\n",
    "        Y = Y.reshape(32,1)[:,0].to(device, dtype=torch.int64)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "        writer.add_scalar('training loss', avg_cost, epoch)\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading testset...\n",
      "testset is ready!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading testset...\")\n",
    "\n",
    "testset = MFCCDataset(test_set)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "   testset, batch_size = batch_size, num_workers = num_workers, drop_last=True\n",
    ")\n",
    "print(\"testset is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.7723076939582825\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = testset.data.view(len(testset), 1, 100, 500).float().to(device)\n",
    "    Y_test = testset.label.to(device, dtype=torch.int64)[:,0]\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}